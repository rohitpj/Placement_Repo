{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Organization: Matrix Structure\n",
    "\n",
    ">**Reference**: Hsiang-Fu Yu, Nikhil Rao, Inderjit S. Dhillon, 2016. [*Temporal regularized matrix factorization for high-dimensional time series prediction*](http://www.cs.utexas.edu/~rofuyu/papers/tr-mf-nips.pdf). 30th Conference on Neural Information Processing Systems (*NIPS 2016*), Barcelona, Spain.\n",
    "\n",
    "We consider a dataset of $m$ discrete time series $\\boldsymbol{y}_{i}\\in\\mathbb{R}^{f},i\\in\\left\\{1,2,...,m\\right\\}$. The time series may have missing elements. We express spatio-temporal dataset as a matrix $Y\\in\\mathbb{R}^{m\\times f}$ with $m$ rows (e.g., locations) and $f$ columns (e.g., discrete time intervals),\n",
    "\n",
    "$$Y=\\left[ \\begin{array}{cccc} y_{11} & y_{12} & \\cdots & y_{1f} \\\\ y_{21} & y_{22} & \\cdots & y_{2f} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ y_{m1} & y_{m2} & \\cdots & y_{mf} \\\\ \\end{array} \\right]\\in\\mathbb{R}^{m\\times f}.$$\n",
    "\n",
    "# Temporal Regularized Matrix Factorization(TRMF)\n",
    "Temporal Regularized Matrix Factorization (TRMF) framework is an approach to incorporate temporal dependencies into matrix factorization models which use well-studied time series models to describe temporal dependencies\n",
    "among ${\\boldsymbol{x}_t}$ explicitly.Such models take the form:\n",
    "\n",
    "$$\\boldsymbol{x}_{t}\\approx\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}$$\n",
    "\n",
    "where this autoregressive (AR) is specialized by a lag set $\\mathcal{L}=\\left\\{l_1,l_2,...,l_d\\right\\}$ (e.g., $\\mathcal{L}=\\left\\{1,2,144\\right\\}$) and weights $\\boldsymbol{\\theta}_{l}\\in\\mathbb{R}^{r},\\forall l$, and we further define\n",
    "\n",
    "$$\\mathcal{R}_{AR}\\left(X\\mid \\mathcal{L},\\Theta,\\eta\\right)=\\frac{1}{2}\\sum_{t=l_d+1}^{f}\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)^T\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)+\\frac{\\eta}{2}\\sum_{t=1}^{f}\\boldsymbol{x}_{t}^T\\boldsymbol{x}_{t}.$$\n",
    "\n",
    "Thus, TRMF-AR is given by solving\n",
    "\n",
    "$$\\min_{W,X,\\Theta}\\frac{1}{2}\\underbrace{\\sum_{(i,t)\\in\\Omega}\\left(y_{it}-\\boldsymbol{w}_{i}^T\\boldsymbol{x}_{t}\\right)^2}_{\\text{sum of squared residual errors}}+\\lambda_{w}\\underbrace{\\mathcal{R}_{w}\\left(W\\right)}_{W-\\text{regularizer}}+\\lambda_{x}\\underbrace{\\mathcal{R}_{AR}\\left(X\\mid \\mathcal{L},\\Theta,\\eta\\right)}_{\\text{AR-regularizer}}+\\lambda_{\\theta}\\underbrace{\\mathcal{R}_{\\theta}\\left(\\Theta\\right)}_{\\Theta-\\text{regularizer}}$$\n",
    "\n",
    "where $\\mathcal{R}_{w}\\left(W\\right)=\\frac{1}{2}\\sum_{i=1}^{m}\\boldsymbol{w}_{i}^T\\boldsymbol{w}_{i}$ and $\\mathcal{R}_{\\theta}\\left(\\Theta\\right)=\\frac{1}{2}\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}^T\\boldsymbol{\\theta}_{l}$ are regularization terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Computation Concepts\n",
    "\n",
    "## Kronecker product\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "Given two matrices $A\\in\\mathbb{R}^{m_1\\times n_1}$ and $B\\in\\mathbb{R}^{m_2\\times n_2}$, then, the **Kronecker product** between these two matrices is defined as\n",
    "\n",
    "$$A\\otimes B=\\left[ \\begin{array}{cccc} a_{11}B & a_{12}B & \\cdots & a_{1m_2}B \\\\ a_{21}B & a_{22}B & \\cdots & a_{2m_2}B \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m_11}B & a_{m_12}B & \\cdots & a_{m_1m_2}B \\\\ \\end{array} \\right]$$\n",
    "where the symbol $\\otimes$ denotes Kronecker product, and the size of resulted $A\\otimes B$ is $(m_1m_2)\\times (n_1n_2)$ (i.e., $m_1\\times m_2$ columns and $n_1\\times n_2$ rows).\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "If $A=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]$ and $B=\\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10 \\\\ \\end{array} \\right]$, then, we have\n",
    "\n",
    "$$A\\otimes B=\\left[ \\begin{array}{cc} 1\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] & 2\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] \\\\ 3\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] & 4\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] \\\\ \\end{array} \\right]$$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cccccc} 5 & 6 & 7 & 10 & 12 & 14 \\\\ 8 & 9 & 10 & 16 & 18 & 20 \\\\ 15 & 18 & 21 & 20 & 24 & 28 \\\\ 24 & 27 & 30 & 32 & 36 & 40 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{4\\times 6}.$$\n",
    "\n",
    "## Khatri-Rao product (`kr_prod`)\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "Given two matrices $A=\\left( \\boldsymbol{a}_1,\\boldsymbol{a}_2,...,\\boldsymbol{a}_r \\right)\\in\\mathbb{R}^{m\\times r}$ and $B=\\left( \\boldsymbol{b}_1,\\boldsymbol{b}_2,...,\\boldsymbol{b}_r \\right)\\in\\mathbb{R}^{n\\times r}$ with same number of columns, then, the **Khatri-Rao product** (or **column-wise Kronecker product**) between $A$ and $B$ is given as follows,\n",
    "\n",
    "$$A\\odot B=\\left( \\boldsymbol{a}_1\\otimes \\boldsymbol{b}_1,\\boldsymbol{a}_2\\otimes \\boldsymbol{b}_2,...,\\boldsymbol{a}_r\\otimes \\boldsymbol{b}_r \\right)\\in\\mathbb{R}^{(mn)\\times r}$$\n",
    "where the symbol $\\odot$ denotes Khatri-Rao product, and $\\otimes$ denotes Kronecker product.\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "If $A=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]=\\left( \\boldsymbol{a}_1,\\boldsymbol{a}_2 \\right) $ and $B=\\left[ \\begin{array}{cc} 5 & 6 \\\\ 7 & 8 \\\\ 9 & 10 \\\\ \\end{array} \\right]=\\left( \\boldsymbol{b}_1,\\boldsymbol{b}_2 \\right) $, then, we have\n",
    "\n",
    "$$A\\odot B=\\left( \\boldsymbol{a}_1\\otimes \\boldsymbol{b}_1,\\boldsymbol{a}_2\\otimes \\boldsymbol{b}_2 \\right) $$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cc} \\left[ \\begin{array}{c} 1 \\\\ 3 \\\\ \\end{array} \\right]\\otimes \\left[ \\begin{array}{c} 5 \\\\ 7 \\\\ 9 \\\\ \\end{array} \\right] & \\left[ \\begin{array}{c} 2 \\\\ 4 \\\\ \\end{array} \\right]\\otimes \\left[ \\begin{array}{c} 6 \\\\ 8 \\\\ 10 \\\\ \\end{array} \\right] \\\\ \\end{array} \\right]$$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cc} 5 & 12 \\\\ 7 & 16 \\\\ 9 & 20 \\\\ 15 & 24 \\\\ 21 & 32 \\\\ 27 & 40 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{6\\times 2}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kr_prod(a, b):\n",
    "    return np.einsum('ir, jr -> ijr', a, b).reshape(a.shape[0] * b.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 12]\n",
      " [ 7 16]\n",
      " [ 9 20]\n",
      " [15 24]\n",
      " [21 32]\n",
      " [27 40]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8], [9, 10]])\n",
    "print(kr_prod(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRMF(dense_mat, sparse_mat, W, X, theta, time_lags, lambda_w, lambda_x, lambda_theta, eta, maxiter):\n",
    "    dim1 = sparse_mat.shape[0]\n",
    "    dim2 = sparse_mat.shape[1]\n",
    "    binary_mat = np.zeros((dim1,dim2))\n",
    "    position = np.where((sparse_mat > 0))\n",
    "    binary_mat[position] = 1\n",
    "    pos = np.where((dense_mat > 0) & (sparse_mat == 0))\n",
    "    d = len(time_lags)\n",
    "    r = theta.shape[1]\n",
    "\n",
    "    mape = np.zeros(maxiter)\n",
    "    rmse = np.zeros(maxiter)\n",
    "    for iter in range(maxiter):\n",
    "        var1 = X.T;\n",
    "        var2 = kr_prod(var1,var1)\n",
    "        var3 = np.matmul(var2,binary_mat.T)\n",
    "        var4 = np.matmul(var1,sparse_mat.T)\n",
    "        for i in range(dim1):\n",
    "            W[i,:] = np.matmul(np.linalg.inv((var3[:,i].reshape([r,r]))+lambda_w * np.eye(r)), var4[:,i])\n",
    "\n",
    "        var1 = W.T\n",
    "        var2 = kr_prod(var1,var1)\n",
    "        var3 = np.matmul(var2, binary_mat)\n",
    "        var4 = np.matmul(var1, sparse_mat)\n",
    "        for t in range(dim2):\n",
    "            Mt = np.zeros((r,r))\n",
    "            Nt = np.zeros(r)\n",
    "            if t < max(time_lags):\n",
    "                Pt = np.zeros((r,r))\n",
    "                Qt = np.zeros(r)\n",
    "            else:\n",
    "                Pt = np.eye(r)\n",
    "                Qt = np.einsum('ij, ij -> j', theta, X[t - time_lags, :])\n",
    "            if t < dim2 - np.min(time_lags):\n",
    "                if t >= np.max(time_lags) and t < dim2 - np.max(time_lags):\n",
    "                    index = list(range(0, d))\n",
    "                else:\n",
    "                    index = list(np.where((t + time_lags >= np.max(time_lags)) & (t + time_lags < dim2)))[0]\n",
    "                for k in index:\n",
    "                    theta0 = theta.copy()\n",
    "                    theta0[k, :] = 0\n",
    "                    Mt = Mt + np.diag(theta[k, :]**2);\n",
    "                    Nt = Nt + np.multiply(theta[k,:],(X[t+time_lags[k], :] \n",
    "                                                                 - np.einsum('ij, ij -> j', theta0,\n",
    "                                                                             X[t + time_lags[k] - time_lags, :])))\n",
    "                X[t,:] = np.matmul(np.linalg.inv(var3[:, t].reshape([r,r])\n",
    "                                                 + lambda_x * Pt + lambda_x * Mt + lambda_x * eta * np.eye(r)),\n",
    "                                   (var4[:, t] + lambda_x * Qt + lambda_x * Nt))\n",
    "            elif t >= dim2 - np.min(time_lags):\n",
    "                X[t, :] = np.matmul(np.linalg.inv(var3[:, t].reshape([r, r])\n",
    "                                                  + lambda_x * Pt +\n",
    "                                                  lambda_x * eta * np.eye(r)), (var4[:, t] + Qt))\n",
    "        for k in range(d):\n",
    "            var1 = X[np.max(time_lags) - time_lags[k] : dim2 - time_lags[k], :]\n",
    "            var2 = np.linalg.inv(np.diag(np.einsum('ij, ij -> j', var1, var1))\n",
    "                                 + (lambda_theta / lambda_x) * np.eye(r))\n",
    "            var3 = np.zeros(r)\n",
    "\n",
    "            for t in range(np.max(time_lags) - time_lags[k], dim2 - time_lags[k]):\n",
    "                var3 = var3 + np.multiply(X[t, :],\n",
    "                                          (X[t + time_lags[k], :] \n",
    "                                           - np.einsum('ij, ij -> j', theta, X[t + time_lags[k] - time_lags, :])\n",
    "                                           +np.multiply(theta[k, :], X[t,:])))\n",
    "            theta[k, :] = np.matmul(var2,var3)\n",
    "\n",
    "        mat_hat = np.matmul(W, X.T)\n",
    "        mape[iter] = np.sum(np.abs(dense_mat[pos] - mat_hat[pos]) / dense_mat[pos]) / dense_mat[pos].shape[0]\n",
    "        rmse[iter] = np.sqrt(np.sum((dense_mat[pos] - mat_hat[pos])**2)/dense_mat[pos].shape[0])\n",
    "    return W, X, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def st_prediction(dense_mat, sparse_mat, time_lags, lambda_w, lambda_x, lambda_theta, eta, rank, pred_time_steps, back_steps, maxiter1, maxiter2):\n",
    "    start_time = dense_mat.shape[1] - pred_time_steps\n",
    "    dense_mat0 = dense_mat[:, 0 : start_time] \n",
    "    sparse_mat0 = sparse_mat[:, 0 : start_time]\n",
    "    dim1 = sparse_mat0.shape[0]\n",
    "    dim2 = sparse_mat0.shape[1]\n",
    "    mat_hat = np.zeros((dim1, pred_time_steps))\n",
    "    \n",
    "    W = 0.1 * np.random.randn(dim1, rank)\n",
    "    X = 0.1 * np.random.randn(dim2, rank)\n",
    "    theta = 0.1 * np.random.randn(d, rank)\n",
    "    \n",
    "    W, X, theta = TRMF(dense_mat0, sparse_mat0, W, X, theta, time_lags, lambda_w, lambda_x, lambda_theta, eta, maxiter1)\n",
    "    \n",
    "    W_p = W.copy()\n",
    "    theta_p = theta.copy()\n",
    "    X0 = np.zeros((dim2 + 1, rank))\n",
    "    X0[0 : dim2, :] = X.copy()\n",
    "    X0[dim2, :] = np.einsum('ij, ij -> j', theta, X0[dim2 - time_lags, :])\n",
    "    X_p = X0[X0.shape[0] - back_steps : X0.shape[0], :] \n",
    "    mat_hat[:, 0] = np.matmul(W, X0[dim2, :])\n",
    "    \n",
    "    for t in range(1, pred_time_steps):\n",
    "        dense_mat1 = dense_mat[:, start_time - back_steps + t : start_time + t]\n",
    "        sparse_mat1 = sparse_mat[:, start_time - back_steps + t : start_time + t]\n",
    "        W, X, theta = TRMF(dense_mat1, sparse_mat1, W_p, X_p, theta_p, time_lags, lambda_w, lambda_x, lambda_theta, eta, maxiter2)\n",
    "        W_p = W.copy()\n",
    "        theta_p = theta.copy()\n",
    "        X0 = np.zeros((back_steps + 1, rank))\n",
    "        X0[0 : back_steps, :] = X.copy()\n",
    "        X0[back_steps, :] = np.einsum('ij, ij -> j', theta, X0[back_steps - time_lags, :])\n",
    "        X_p = X0[1: back_steps + 1, :]\n",
    "        mat_hat[:, t] = np.matmul(W, X0[back_steps, :])\n",
    "        if (t + 1) % 40 == 0:\n",
    "            print('Time step: {}'.format(t + 1))\n",
    "\n",
    "    small_dense_mat = dense_mat[:, start_time : dense_mat.shape[1]]\n",
    "    pos = np.where(small_dense_mat > 0)\n",
    "    final_mape = np.sum(np.abs(small_dense_mat[pos] - \n",
    "                               mat_hat[pos])/small_dense_mat[pos])/small_dense_mat[pos].shape[0]\n",
    "    final_rmse = np.sqrt(np.sum((small_dense_mat[pos] - \n",
    "                                 mat_hat[pos]) ** 2)/small_dense_mat[pos].shape[0])\n",
    "    print('Final MAPE: {:.6}'.format(final_mape))\n",
    "    print('Final RMSE: {:.6}'.format(final_rmse))\n",
    "    print()\n",
    "    return mat_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('Hangzhou-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('Hangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('Hangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "# binary_mat = np.round(random_tensor + 0.5 - missing_rate).reshape([random_tensor.shape[0], \n",
    "#                                                                    random_tensor.shape[1] \n",
    "#                                                                    * random_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(tensor.shape)\n",
    "for i1 in range(tensor.shape[0]):\n",
    "    for i2 in range(tensor.shape[1]):\n",
    "        binary_tensor[i1,i2,:] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] \n",
    "                                    * binary_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vader\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\vader\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:68: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step: 40\n",
      "Time step: 80\n",
      "Time step: 120\n",
      "Time step: 160\n",
      "Time step: 200\n",
      "Time step: 240\n",
      "Time step: 280\n",
      "Time step: 320\n",
      "Time step: 360\n",
      "Time step: 400\n",
      "Time step: 440\n",
      "Time step: 480\n",
      "Time step: 520\n",
      "Time step: 560\n",
      "Time step: 600\n",
      "Time step: 640\n",
      "Time step: 680\n",
      "Time step: 720\n",
      "Final MAPE: 0.235035\n",
      "Final RMSE: 35.0231\n",
      "\n",
      "Running time: 19115 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 144 * 5\n",
    "back_steps = 144 * 2 \n",
    "time_lags = np.array([1, 2, 108])\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 20\n",
    "lambda_w = 7\n",
    "lambda_x = 7\n",
    "lambda_theta = 7\n",
    "eta = 0.03\n",
    "d = time_lags.shape[0]\n",
    "\n",
    "maxiter1 = 1000\n",
    "maxiter2 = 200\n",
    "#sparse matrix scenario\n",
    "#mat_hat = st_prediction(dense_mat, sparse_mat, time_lags, lambda_w, lambda_x, lambda_theta, eta, rank, pred_time_steps, back_steps, maxiter1, maxiter2)\n",
    "#dense matrix scenario\n",
    "mat_hat = st_prediction(dense_mat, dense_mat, time_lags, lambda_w, lambda_x, lambda_theta, eta, rank, pred_time_steps, back_steps, maxiter1, maxiter2)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (12, 2.5))\n",
    "road = 3\n",
    "plt.plot(Xt[road, :], 'r', \n",
    "         small_dense_mat[road, :], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.33333333,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.5       ,  0.        ,  0.        ],\n",
       "       [-0.        , -0.        , -0.        ,  0.25      , -0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.2       ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,3,2,4,5])\n",
    "B = np.diag(a)\n",
    "C = np.linalg.inv(B)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of spatial-temporal data prediction using online TRMF:\n",
    "\n",
    "|  scenario |`rank`|`Lambda_w`|`Lambda_x`|`Lambda_theta`|`eta`|`maxiter`|`back step`|         mape |        rmse |\n",
    "|:----------|-----:|---------:|---------:|-------------:|----:|---------:|----------:|-------------:|------------:|\n",
    "|**Original data**|   10 |        5 |        5 |            5 | 0.03|(1000,200)|   144 * 2 |  **0.235035**| **35.0231**|\n",
    "|**20%, RM**|   10 |        5 |        5 |            5 | 0.03|(1000,200)|   144 * 2 |  **0.255117**| **42.2614**|\n",
    "|**20%, RM**|   10 |        6 |        6 |            6 | 0.03|(1000,200)|   144 * 2 |  **0.248802**| **41.2168**|\n",
    "|**20%, RM**|   10 |        7 |        7 |            7 | 0.03|(1000,200)|   144 * 2 |  **0.245255**| **39.8855**|\n",
    "|**20%, RM**|   10 |        7 |        7 |            7 | 0.04|(1000,200)|   144 * 2 |  **0.253674**| **40.8621**|\n",
    "|**20%, RM**|   15 |        7 |        7 |            7 | 0.03|(1000,200)|   144 * 2 |  **0.234144**| **35.4999**|\n",
    "|**20%, RM**|   15 |        7 |        7 |            7 | 0.04|(1000,200)|   144 * 2 |  **0.251952**| **40.2934**|\n",
    "|**20%, RM**|   20 |        7 |        7 |            7 | 0.03|(1000,200)|   144 * 2 |  **0.236752**| **35.1934**|\n",
    "|**20%, RM**|   20 |        7 |        7 |            7 | 0.04|(1000,200)|   144 * 2 |  **0.259573**| **42.508**|\n",
    "|**20%, RM**|   25 |        7 |        7 |            7 | 0.03|(1000,200)|   144 * 2 |  **0.240533**| **35.8572**|\n",
    "|**20%, RM**|   10 |       10 |       10 |           10 | 0.03|(1000,200)|   144 * 2 |  **0.248508**| **40.1612**|\n",
    "|**20%, RM**|   10 |      900 |      900 |          900 | 0.03|(1000,200)|   144 * 2 |  **0.362184**| **63.965**|\n",
    "|**40%, RM**|   20 |        7 |        7 |            7 | 0.03|(1000,200)|   144 * 2 |  **0.305683**| **47.9195**|\n",
    "|**20%, NM**|   20 |        7 |        7 |            7 | 0.03|(1000,200)|   144 * 2 |  **0.235035**| **35.0231**|\n",
    "|**40%, NM**|   20 |        7 |        7 |            7 | 0.03|(1000,200)|   144 * 2 |  **0.363618**| **60.5493**|\n",
    "\n",
    "   > The experiment relies on the *Urban traffic speed data set in Hangzhou, China*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
