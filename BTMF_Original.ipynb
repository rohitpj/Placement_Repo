{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Temporal Matrix Factorization Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Sampling Factor Matrix $W$ and Its Hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For programming convenience, we use $W\\in\\mathbb{R}^{N\\times R}$ to replace $W\\in\\mathbb{R}^{R\\times N}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv as inv\n",
    "from numpy.random import normal as normrnd\n",
    "from scipy.linalg import khatri_rao as kr_prod\n",
    "from scipy.stats import wishart\n",
    "from scipy.stats import invwishart\n",
    "from numpy.linalg import solve as solve\n",
    "from numpy.linalg import cholesky as cholesky_lower\n",
    "from scipy.linalg import cholesky as cholesky_upper\n",
    "from scipy.linalg import solve_triangular as solve_ut\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvnrnd_pre(mu, Lambda):\n",
    "    src = normrnd(size = (mu.shape[0],))\n",
    "    return solve_ut(cholesky_upper(Lambda, overwrite_a = True, check_finite = False), \n",
    "                    src, lower = False, check_finite = False, overwrite_b = True) + mu\n",
    "\n",
    "def cov_mat(mat, mat_bar):\n",
    "    mat = mat - mat_bar\n",
    "    return mat.T @ mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_factor_w(tau_sparse_mat, tau_ind, W, X, tau, beta0 = 1, vargin = 0):\n",
    "    \"\"\"Sampling N-by-R factor matrix W and its hyperparameters (mu_w, Lambda_w).\"\"\"\n",
    "    \n",
    "    dim1, rank = W.shape\n",
    "    W_bar = np.mean(W, axis = 0)\n",
    "    temp = dim1 / (dim1 + beta0)\n",
    "    var_W_hyper = inv(np.eye(rank) + cov_mat(W, W_bar) + temp * beta0 * np.outer(W_bar, W_bar))\n",
    "    var_Lambda_hyper = wishart.rvs(df = dim1 + rank, scale = var_W_hyper)\n",
    "    var_mu_hyper = mvnrnd_pre(temp * W_bar, (dim1 + beta0) * var_Lambda_hyper)\n",
    "    \n",
    "    if dim1 * rank ** 2 > 1e+8:\n",
    "        vargin = 1\n",
    "    \n",
    "    if vargin == 0:\n",
    "        var1 = X.T\n",
    "        var2 = kr_prod(var1, var1)\n",
    "        var3 = (var2 @ tau_ind.T).reshape([rank, rank, dim1]) + var_Lambda_hyper[:, :, None]\n",
    "        var4 = var1 @ tau_sparse_mat.T + (var_Lambda_hyper @ var_mu_hyper)[:, None]\n",
    "        for i in range(dim1):\n",
    "            W[i, :] = mvnrnd_pre(solve(var3[:, :, i], var4[:, i]), var3[:, :, i])\n",
    "    elif vargin == 1:\n",
    "        for i in range(dim1):\n",
    "            pos0 = np.where(sparse_mat[i, :] != 0)\n",
    "            Xt = X[pos0[0], :]\n",
    "            var_mu = tau[i] * Xt.T @ sparse_mat[i, pos0[0]] + var_Lambda_hyper @ var_mu_hyper\n",
    "            var_Lambda = tau[i] * Xt.T @ Xt + var_Lambda_hyper\n",
    "            W[i, :] = mvnrnd_pre(solve(var_Lambda, var_mu), var_Lambda)\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnrnd(M, U, V):\n",
    "    \"\"\"\n",
    "    Generate matrix normal distributed random matrix.\n",
    "    M is a m-by-n matrix, U is a m-by-m matrix, and V is a n-by-n matrix.\n",
    "    \"\"\"\n",
    "    dim1, dim2 = M.shape\n",
    "    X0 = np.random.randn(dim1, dim2)\n",
    "    P = cholesky_lower(U)\n",
    "    Q = cholesky_lower(V)\n",
    "    \n",
    "    return M + P @ X0 @ Q.T\n",
    "\n",
    "def sample_var_coefficient(X, time_lags):\n",
    "    dim, rank = X.shape\n",
    "    d = time_lags.shape[0]\n",
    "    tmax = np.max(time_lags)\n",
    "    \n",
    "    Z_mat = X[tmax : dim, :]\n",
    "    Q_mat = np.zeros((dim - tmax, rank * d))\n",
    "    for k in range(d):\n",
    "        Q_mat[:, k * rank : (k + 1) * rank] = X[tmax - time_lags[k] : dim - time_lags[k], :]\n",
    "    var_Psi0 = np.eye(rank * d) + Q_mat.T @ Q_mat\n",
    "    var_Psi = inv(var_Psi0)\n",
    "    var_M = var_Psi @ Q_mat.T @ Z_mat\n",
    "    var_S = np.eye(rank) + Z_mat.T @ Z_mat - var_M.T @ var_Psi0 @ var_M\n",
    "    Sigma = invwishart.rvs(df = rank + dim - tmax, scale = var_S)\n",
    "    \n",
    "    return mnrnd(var_M, var_Psi, Sigma), Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_factor_x(tau_sparse_mat, tau_ind, time_lags, W, X, A, Lambda_x):\n",
    "    \"\"\"Sampling T-by-R factor matrix X.\"\"\"\n",
    "    \n",
    "    dim2, rank = X.shape\n",
    "    tmax = np.max(time_lags)\n",
    "    tmin = np.min(time_lags)\n",
    "    d = time_lags.shape[0]\n",
    "    A0 = np.dstack([A] * d)\n",
    "    for k in range(d):\n",
    "        A0[k * rank : (k + 1) * rank, :, k] = 0\n",
    "    mat0 = Lambda_x @ A.T\n",
    "    mat1 = np.einsum('kij, jt -> kit', A.reshape([d, rank, rank]), Lambda_x)\n",
    "    mat2 = np.einsum('kit, kjt -> ij', mat1, A.reshape([d, rank, rank]))\n",
    "    \n",
    "    var1 = W.T\n",
    "    var2 = kr_prod(var1, var1)\n",
    "    var3 = (var2 @ tau_ind).reshape([rank, rank, dim2]) + Lambda_x[:, :, None]\n",
    "    var4 = var1 @ tau_sparse_mat\n",
    "    for t in range(dim2):\n",
    "        Mt = np.zeros((rank, rank))\n",
    "        Nt = np.zeros(rank)\n",
    "        Qt = mat0 @ X[t - time_lags, :].reshape(rank * d)\n",
    "        index = list(range(0, d))\n",
    "        if t >= dim2 - tmax and t < dim2 - tmin:\n",
    "            index = list(np.where(t + time_lags < dim2))[0]\n",
    "        elif t < tmax:\n",
    "            Qt = np.zeros(rank)\n",
    "            index = list(np.where(t + time_lags >= tmax))[0]\n",
    "        if t < dim2 - tmin:\n",
    "            Mt = mat2.copy()\n",
    "            temp = np.zeros((rank * d, len(index)))\n",
    "            n = 0\n",
    "            for k in index:\n",
    "                temp[:, n] = X[t + time_lags[k] - time_lags, :].reshape(rank * d)\n",
    "                n += 1\n",
    "            temp0 = X[t + time_lags[index], :].T - np.einsum('ijk, ik -> jk', A0[:, :, index], temp)\n",
    "            Nt = np.einsum('kij, jk -> i', mat1[index, :, :], temp0)\n",
    "        \n",
    "        var3[:, :, t] = var3[:, :, t] + Mt\n",
    "        if t < tmax:\n",
    "            var3[:, :, t] = var3[:, :, t] - Lambda_x + np.eye(rank)\n",
    "        X[t, :] = mvnrnd_pre(solve(var3[:, :, t], var4[:, t] + Nt + Qt), var3[:, :, t])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Sampling Precision $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_precision_tau(sparse_mat, mat_hat, ind):\n",
    "    var_alpha = 1e-6 + 0.5 * np.sum(ind, axis = 1)\n",
    "    var_beta = 1e-6 + 0.5 * np.sum(((sparse_mat - mat_hat) ** 2) * ind, axis = 1)\n",
    "    return np.random.gamma(var_alpha, 1 / var_beta)\n",
    "\n",
    "def sample_precision_scalar_tau(sparse_mat, mat_hat, ind):\n",
    "    var_alpha = 1e-6 + 0.5 * np.sum(ind)\n",
    "    var_beta = 1e-6 + 0.5 * np.sum(((sparse_mat - mat_hat) ** 2) * ind)\n",
    "    return np.random.gamma(var_alpha, 1 / var_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) BTMF Implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BTMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter, option = \"factor\"):\n",
    "    \"\"\"Bayesian Temporal Matrix Factorization, BTMF.\"\"\"\n",
    "    \n",
    "    dim1, dim2 = sparse_mat.shape\n",
    "    print(\"dense_mat shape\",dense_mat.shape)\n",
    "    d = time_lags.shape[0]\n",
    "    W = init[\"W\"]\n",
    "    X = init[\"X\"]\n",
    "\n",
    "    if np.isnan(sparse_mat).any() == False:\n",
    "        ind = sparse_mat != 0\n",
    "        pos_obs = np.where(ind)\n",
    "        pos_test = np.where((dense_mat != 0) & (sparse_mat == 0))\n",
    "\n",
    "        print(\"pos test  shape: \", pos_test)\n",
    "    elif np.isnan(sparse_mat).any() == True:\n",
    "        pos_test = np.where((dense_mat != 0) & (np.isnan(sparse_mat)))\n",
    "        ind = ~np.isnan(sparse_mat)\n",
    "        pos_obs = np.where(ind)\n",
    "        sparse_mat[np.isnan(sparse_mat)] = 0\n",
    "\n",
    "    dense_test = dense_mat[pos_test]\n",
    "    print(\"dense_test shape\", dense_test.shape)\n",
    "    del dense_mat\n",
    "    tau = np.ones(dim1)\n",
    "    W_plus = np.zeros((dim1, rank))\n",
    "    X_plus = np.zeros((dim2, rank))\n",
    "    A_plus = np.zeros((rank * d, rank))\n",
    "    temp_hat = np.zeros(len(pos_test[0]))\n",
    "    show_iter = 999\n",
    "    mat_hat_plus = np.zeros((dim1, dim2))\n",
    "    for it in range(burn_iter + gibbs_iter):\n",
    "        print(\"iteration:\",it)\n",
    "        tau_ind = tau[:, None] * ind\n",
    "        tau_sparse_mat = tau[:, None] * sparse_mat\n",
    "        W = sample_factor_w(tau_sparse_mat, tau_ind, W, X, tau)\n",
    "        A, Sigma = sample_var_coefficient(X, time_lags)\n",
    "        X = sample_factor_x(tau_sparse_mat, tau_ind, time_lags, W, X, A, inv(Sigma))\n",
    "        mat_hat = W @ X.T\n",
    "        if option == \"factor\":\n",
    "            tau = sample_precision_tau(sparse_mat, mat_hat, ind)\n",
    "        elif option == \"pca\":\n",
    "            tau = sample_precision_scalar_tau(sparse_mat, mat_hat, ind)\n",
    "            tau = tau * np.ones(dim1)\n",
    "        temp_hat += mat_hat[pos_test]\n",
    "        if (it + 1) % show_iter == 0 and it < burn_iter:\n",
    "            temp_hat = temp_hat / show_iter\n",
    "            print(\"dense test shape: \", dense_test.shape)\n",
    "            print(\"temp_hat shape: \", temp_hat.shape)\n",
    "            print('Iter: {}'.format(it + 1))\n",
    "            print('MAPE: {:.6}'.format(compute_mape(dense_test, temp_hat)))\n",
    "            print('RMSE: {:.6}'.format(compute_rmse(dense_test, temp_hat)))\n",
    "            temp_hat = np.zeros(len(pos_test[0]))\n",
    "            print()\n",
    "        if it + 1 > burn_iter:\n",
    "            W_plus += W\n",
    "            X_plus += X\n",
    "            A_plus += A\n",
    "            mat_hat_plus += mat_hat\n",
    "    mat_hat = mat_hat_plus / gibbs_iter\n",
    "    W = W_plus / gibbs_iter\n",
    "    X = X_plus / gibbs_iter\n",
    "    A = A_plus / gibbs_iter\n",
    "    #print('Imputation MAPE: {:.6}'.format(compute_mape(dense_test, mat_hat[:, : dim2][pos_test])))\n",
    "    #print('Imputation RMSE: {:.6}'.format(compute_rmse(dense_test, mat_hat[:, : dim2][pos_test])))\n",
    "    #print()\n",
    "    mat_hat[mat_hat < 0] = 0\n",
    "    \n",
    "    return mat_hat, W, X, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Guangzhou Speed Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('C:/Users/Rohit/Documents/Exeter-Placement/transdim-master/datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "dim = dense_tensor.shape\n",
    "missing_rate = 0.4 # Non-random missing (NM)\n",
    "sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1])[:, :, np.newaxis] + 0.5 - missing_rate)\n",
    "dense_mat = dense_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "sparse_mat = sparse_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "del dense_tensor, sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "df = pd.read_excel('C:/Users/Rohit/Documents/Exeter-Placement/Archive_Data/Gen_Demand_Data_Sc3_Chausey_Scenario1-Copy.xlsx', engine='openpyxl')\n",
    "dense_mat = df.values\n",
    "\n",
    "# Handle missing values (assuming NaN represents missing values in your .xlsx file)\n",
    "sparse_mat = np.copy(dense_mat)\n",
    "sparse_mat[np.isnan(dense_mat)] = 0.0000001  # Set NaNs to 0 for the sparse matrix\n",
    "sparse_mat[np.where(dense_mat==0)] = 0.0000001  # Set NaNs to 0 for the sparse matrix\n",
    "\n",
    "dense_mat = dense_mat.T\n",
    "sparse_mat = sparse_mat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_mat shape (6, 8759)\n",
      "pos test  shape:  (array([], dtype=int64), array([], dtype=int64))\n",
      "dense_test shape (0,)\n",
      "iteration: 0\n",
      "iteration: 1\n",
      "iteration: 2\n",
      "iteration: 3\n",
      "iteration: 4\n",
      "iteration: 5\n",
      "iteration: 6\n",
      "iteration: 7\n",
      "iteration: 8\n",
      "iteration: 9\n",
      "iteration: 10\n",
      "iteration: 11\n",
      "Running time: 12 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 144])\n",
    "init = {\"W\": 0.01 * np.random.randn(dim1, rank), \"X\": 0.01 * np.random.randn(dim2, rank)}\n",
    "burn_iter = 10\n",
    "gibbs_iter = 2\n",
    "mat_hat, W, X, A = BTMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter)\n",
    "mat_hat=mat_hat.T\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))\n",
    "df_mat_hat = pd.DataFrame(mat_hat)\n",
    "with pd.ExcelWriter('mat_hat_output.xlsx', engine='openpyxl') as writer:\n",
    "    df_mat_hat.to_excel(writer, sheet_name='Sheet1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Placement links'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     lines \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mreadlines()\n\u001b[0;32m     10\u001b[0m \u001b[39m# Depending on the structure of your .tsf file, extract the data\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# For this example, let's assume each line is a separate time series data point\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m data \u001b[39m=\u001b[39m [\u001b[39mfloat\u001b[39;49m(line\u001b[39m.\u001b[39;49mstrip()) \u001b[39mfor\u001b[39;49;00m line \u001b[39min\u001b[39;49;00m lines]\n\u001b[0;32m     14\u001b[0m \u001b[39m# Convert to DataFrame\u001b[39;00m\n\u001b[0;32m     15\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mTime Series Data\u001b[39m\u001b[39m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[16], line 12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m     lines \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mreadlines()\n\u001b[0;32m     10\u001b[0m \u001b[39m# Depending on the structure of your .tsf file, extract the data\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# For this example, let's assume each line is a separate time series data point\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m data \u001b[39m=\u001b[39m [\u001b[39mfloat\u001b[39;49m(line\u001b[39m.\u001b[39;49mstrip()) \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines]\n\u001b[0;32m     14\u001b[0m \u001b[39m# Convert to DataFrame\u001b[39;00m\n\u001b[0;32m     15\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mTime Series Data\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Placement links'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the .tsf file\n",
    "\n",
    "with open('C:/Users/Rohit/Documents/Exeter-Placement/phase_1_data/phase_1_data/phase_1_data.tsf', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Depending on the structure of your .tsf file, extract the data\n",
    "# For this example, let's assume each line is a separate time series data point\n",
    "data = [float(line.strip()) for line in lines]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=['Time Series Data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
